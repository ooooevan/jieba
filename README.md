## 学习jieba分词

实现了cut、cutHMM、cutAll、cutForSearch等方法


存在的问题：代码还没整理、cutHMM太慢未优化(字符串太长时构建成树耗时，栈溢出)等等


### 过程中的问题

1、同样的词库，自己的cut(str, true)和hmm方法和官方的结果不一致，cut(str)一样

如: 
```js
str = '到MI京研大厦'
nodejieba.cut(str); // ['到', 'M', 'I', '京', '研', '大厦']
nodejieba.cut(str, true); // ['到', 'MI', '京研', '大厦']
nodejieba.cutHMM(str);  // [ '到', 'MI', '京', '研大厦' ]
cut(str, true);   // [ '到M', 'I京', '研', '大厦' ]
hmm(str);  // ['到M', 'I京', '研大', '厦']
```

通过调试看源码，发现了hmm的两个正则匹配。中英文要区分
```js
/([\u4E00-\u9FD5]+)/;   //将中文和非中文分开
/([a-zA-Z0-9]+(?:\.\d+)?%?)/; //匹配英文数字及其他符号，可以将英文数字和其他字符分开，后面的%符号挺奇怪的，是想匹配百分数吗
/([a-zA-Z0-9]+(?:\.\d)?)|([0-9]+(?:\.\d)?%?)/;  //匹配百分数，数字才能匹配百分号
```
在hmm函数添加了相关代码后，上面的问题解决了

2、hmm函数构建根据BEMS构建树未优化，耗时且太长会导致栈溢出
```js
str = '百度'
// 嵌套太深，且叶子节点数为：2 ** n 字符串长度
// 保留了每一个节点类型的的概率
obj = {
  b:{
    next:{
      e:{},
      m:{}
    }
  },
  s:{
    next:{
      s:{},
      b:{}
    }
  }
}
```

看jieba源码发现，他并没有这样的结构，而是得出最终类型如：`['b','e']`
对比了发现，我实现的方式是:

```js
const tranObj = getWordTree(str); //将字符串转为一个大对象
var tranArr = recursion(tranObj);  //将对象转为数组且是2**n个数组
var conarr = getAppropriate(tranArr); //从2**n个数组中选出最优的一个数组
```
而官方实现的方式只有一个函数，我弄出了很多中间函数，存储了很多无用变量（是最初写时方便理解）
计算中，需要不同方案的总概率最大，是要保留每个的概率，


